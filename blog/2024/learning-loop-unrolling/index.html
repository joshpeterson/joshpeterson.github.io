<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Learning loop unrolling | Josh Peterson </title> <meta name="author" content="Josh Peterson"> <meta name="description" content="Josh's personal website "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%8B&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joshpeterson.github.io/blog/2024/learning-loop-unrolling/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Josh</span> Peterson </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/philosophy/">philosophy </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/repositories/">repositories</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/publications/">publications</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Learning loop unrolling</h1> <p class="post-meta"> Created in February 12, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In the excellent Freakonomics Radio <a href="https://freakonomics.com/podcast-tag/richard-feynman/" rel="external nofollow noopener" target="_blank">podcast series</a> about physicist Richard Feynman (stop reading now an go listen to it!) I heard an interesting tidbit from Feynman:</p> <blockquote> <p>Knowing the name of something doesn’t mean you understand it. (<a href="https://www.youtube.com/watch?v=px_4TxC2mXU" rel="external nofollow noopener" target="_blank">video</a>)</p> </blockquote> <p>After reading a recent blog post from Modular about <a href="https://www.modular.com/blog/what-is-loop-unrolling-how-you-can-speed-up-mojo" rel="external nofollow noopener" target="_blank">loop unrolling</a>, I realized that I know what loop unrolling is, but I don’t really understand it. This post is my journey to a deeper understanding.</p> <h2 id="the-setup">The setup</h2> <p>I decided to start this deep dive with the <a href="https://docs.modular.com/mojo/notebooks/Matmul.html" rel="external nofollow noopener" target="_blank">matrix multiplication documentation</a> for Mojo, to see how loop unrolling impacts the naive “matmul” algorithm.</p> <p>I’m doing all of this on an M2 macOS machine, but the results should apply equally to x64 processors.</p> <p>I’m using a few excellent tools:</p> <ul> <li> <a href="https://ghidra-sre.org/" rel="external nofollow noopener" target="_blank">Ghidra</a> to analyze the assembly code built by Mojo</li> <li> <a href="https://github.com/sharkdp/hyperfine" rel="external nofollow noopener" target="_blank">Hyperfine</a> for benchmarking</li> <li> <a href="https://github.com/mstange/samply" rel="external nofollow noopener" target="_blank">Samply</a> for profiling</li> </ul> <p>I’ll be fiddling with this Mojo code, which depends on the <code class="language-plaintext highlighter-rouge">Matrix</code> type implemented in the documentation linked above, using elements of type <code class="language-plaintext highlighter-rouge">DType.float32</code>. You can find all the code I used for this exploration on <a href="https://github.com/joshpeterson/on-a-roll/tree/main/mojo" rel="external nofollow noopener" target="_blank">Github</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alias</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">1024</span>

<span class="n">fn</span> <span class="nf">matmul_naive</span><span class="p">(</span><span class="n">C</span><span class="p">:</span> <span class="n">Matrix</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">Matrix</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">Matrix</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">C</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
  <span class="n">var</span> <span class="n">C</span> <span class="o">=</span> <span class="nc">Matrix</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
  <span class="n">var</span> <span class="n">A</span> <span class="o">=</span> <span class="n">Matrix</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
  <span class="n">var</span> <span class="n">B</span> <span class="o">=</span> <span class="n">Matrix</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

  <span class="nf">matmul_naive</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
 
  <span class="n">A</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">free</span><span class="p">()</span>
  <span class="n">B</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">free</span><span class="p">()</span>
  <span class="n">C</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">free</span><span class="p">()</span>
</code></pre></div></div> <h2 id="the-wrong-path">The wrong path</h2> <p>Sometimes blog posts make it seem like the author knew what they were doing the whole time. For me at least, this is usually not the case. I’ll start by showing how I went down the wrong path.</p> <p>First, I compiled the code with <code class="language-plaintext highlighter-rouge">mojo build</code>, then used Ghidra to look at the assembly code. Most of the work here is done in this loop (which is the inner-most of the three loops):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LAB_100000c48
ldr        s1,[x15], #0x4
ldr        s2,[x16]
fmadd      s1,s0,s1,s2
str        s1,[x16], #0x4
sub        x17,x17,#0x1
cmp        x17,#0x1
b.hi       LAB_100000c48
</code></pre></div></div> <p>The third instruction - <a href="https://developer.arm.com/documentation/ddi0602/2023-12/SIMD-FP-Instructions/FMADD--Floating-point-fused-Multiply-Add--scalar--?lang=en" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">fmadd</code></a> - is the key one here. It is doing one multiply and one add operation, all in one instruction, on 32-bit floating point values. After the mathematics, the loop counter in the <code class="language-plaintext highlighter-rouge">x17</code> register is decremented, and the code jumps back to the top of the loop for the next iteration.</p> <p>So, I wondered what would happen if I added the <code class="language-plaintext highlighter-rouge">unroll</code> directive to the outer most loop.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fn</span> <span class="nf">matmul_naive</span><span class="p">(</span><span class="n">C</span><span class="p">:</span> <span class="n">Matrix</span><span class="p">,</span> <span class="n">A</span><span class="p">:</span> <span class="n">Matrix</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="n">Matrix</span><span class="p">):</span>
  <span class="nd">@unroll</span> <span class="p">(</span><span class="mi">4</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">C</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span>
</code></pre></div></div> <p>The Mojo compiler dutifully gives me four loops, with three additional copies of the assembly code loop shown above plus some setup and teardown code in between (I’ll avoid showing them here to save space). So this is loop unrolling, cool!</p> <p>The code must be faster now, right? Let’s see what Hyperfine tells us. I benchmarked the implementation without unrolling against unrolling the loop 4, 8, 16, and 32 times.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Benchmark 1: ./matmul
	Time (mean ± σ): 361.3 ms ± 3.1 ms [User: 342.3 ms, System: 2.0 ms]
	Range (min … max): 357.3 ms … 368.2 ms 10 runs

Benchmark 2: ./matmul_unrolled4
	Time (mean ± σ): 387.7 ms ± 1.7 ms [User: 369.3 ms, System: 1.9 ms]
	Range (min … max): 384.9 ms … 389.9 ms 10 runs

Benchmark 3: ./matmul_unrolled8
	Time (mean ± σ): 389.7 ms ± 5.2 ms [User: 373.5 ms, System: 1.7 ms]
	Range (min … max): 376.6 ms … 394.3 ms 10 runs

Benchmark 4: ./matmul_unrolled16
	Time (mean ± σ): 394.7 ms ± 1.5 ms [User: 376.3 ms, System: 1.8 ms]
	Range (min … max): 392.4 ms … 396.7 ms 10 runs

Benchmark 5: ./matmul_unrolled32
	Time (mean ± σ): 422.0 ms ± 2.4 ms [User: 403.4 ms, System: 1.9 ms]
	Range (min … max): 416.3 ms … 425.6 ms 10 runs

Summary
./matmul ran
	1.07 ± 0.01 times faster than ./matmul_unrolled4
	1.08 ± 0.02 times faster than ./matmul_unrolled8
	1.09 ± 0.01 times faster than ./matmul_unrolled16
	1.17 ± 0.01 times faster than ./matmul_unrolled32
</code></pre></div></div> <p>Huh? The code was faster before I started to fiddle with loop unrolling. In all cases, I made the code execute more slowly! I was very confused. Had I read to the end of the Mojo matrix multiply documentation, I would have noticed that <code class="language-plaintext highlighter-rouge">unroll</code> makes more sense on the inner loop than the outer loop. But I instead went on a hunt to better understand loop unrolling in other languages.</p> <p>Thankfully, I stumbled across the ARM C++ compiler documentation for <a href="https://developer.arm.com/documentation/dui0491/i/Compiler-specific-Features/-pragma-unroll---n--" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">#pragma unroll</code></a>](which is how C++ compilers spell <code class="language-plaintext highlighter-rouge">@unroll</code>). Check out this example:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">matrix_multiply</span><span class="p">(</span><span class="kt">float</span> <span class="o">**</span> <span class="kr">__restrict</span> <span class="n">dest</span><span class="p">,</span> <span class="kt">float</span> <span class="o">**</span> <span class="kr">__restrict</span> <span class="n">src1</span><span class="p">,</span> <span class="kt">float</span> <span class="o">**</span> <span class="kr">__restrict</span> <span class="n">src2</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span> 
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">;</span> 
  <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span> 
    <span class="k">for</span> <span class="p">(</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span> 
      <span class="kt">float</span> <span class="n">sum</span> <span class="o">=</span> <span class="mf">0.0</span><span class="n">f</span><span class="p">;</span>
      <span class="cm">/* #pragma unroll */</span> 
      <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> 
        <span class="n">sum</span> <span class="o">+=</span> <span class="n">src1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">src2</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">];</span> <span class="n">dest</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>It looks very similar to the naive matrix multiply implementation in Mojo. You can fiddle with <a href="https://godbolt.org/z/558hMnYKb" rel="external nofollow noopener" target="_blank">this example</a> on Compiler Explorer to see the impact of loop unrolling in C++. It got me to thinking - maybe I should try to unroll the inner-most loop in Mojo as well.</p> <h2 id="getting-it-right">Getting it right</h2> <p>As the Mojo documentation for matrix multiplication suggests, forcing the inner loop to unroll <em>does</em> improve performance. Let’s get straight to the results from Hyperfine:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Benchmark 1: ./matmul
  Time (mean ± σ):     362.0 ms ±   4.1 ms    [User: 341.3 ms, System: 1.8 ms]
  Range (min … max):   356.0 ms … 371.9 ms    10 runs
 
Benchmark 2: ./matmul_unrolled4
  Time (mean ± σ):     128.2 ms ±   3.9 ms    [User: 108.6 ms, System: 1.6 ms]
  Range (min … max):   124.4 ms … 143.4 ms    21 runs
 
Benchmark 3: ./matmul_unrolled8
  Time (mean ± σ):     116.2 ms ±   4.1 ms    [User: 98.3 ms, System: 1.6 ms]
  Range (min … max):   102.8 ms … 119.4 ms    24 runs
 
Benchmark 4: ./matmul_unrolled16
  Time (mean ± σ):     114.3 ms ±   3.9 ms    [User: 95.3 ms, System: 1.6 ms]
  Range (min … max):   104.1 ms … 125.7 ms    22 runs
 
Benchmark 5: ./matmul_unrolled32
  Time (mean ± σ):     114.3 ms ±   2.9 ms    [User: 95.3 ms, System: 1.6 ms]
  Range (min … max):   109.3 ms … 121.7 ms    23 runs
 
Summary
  ./matmul_unrolled32 ran
    1.00 ± 0.04 times faster than ./matmul_unrolled16
    1.02 ± 0.04 times faster than ./matmul_unrolled8
    1.12 ± 0.04 times faster than ./matmul_unrolled4
    3.17 ± 0.09 times faster than ./matmul
</code></pre></div></div> <p>Now this is cool! The unrolled versions all ran about 3 times faster than the naive implementation. But this is not really a complete understanding. Why is the code so much faster with inner loop unrolled? Let’s have a look at the assembly code for that unrolled inner loop.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LAB_100001724                                   
ldr        q1,[x15], #0x10
ldr        q2,[x16]
fmla       v2.4S,v0.4S,v1.4S
str        q2,[x16], #0x10
sub        x17,x17,#0x4
cmp        x17,#0x4
b.hi       LAB_100001724
</code></pre></div></div> <p>Can you spot the difference? It took me a while, so let’s look at the normal code and the unrolled code side by side.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Normal               Unrolled
================== | ======================
ldr s1,[x15], #0x4 | ldr q1,[x15], #0x10
ldr s2,[x16]       | ldr q2,[x16]
fmadd s1,s0,s1,s2  | fmla v2.4S,v0.4S,v1.4S
str s1,[x16], #0x4 | str q2,[x16], #0x10
sub x17,x17,#0x1   | sub x17,x17,#0x4
cmp x17,#0x1       | cmp x17,#0x4
b.hi LAB_100000c48 | b.hi LAB_100001724
</code></pre></div></div> <p>Check out the multiply and add operation, it is spelled differently - <a href="https://developer.arm.com/documentation/ddi0602/2022-06/SVE-Instructions/FMLA--vectors---Floating-point-fused-multiply-add-vectors--predicated---writing-addend--Zda---Zda---Zn---Zm--" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">fmla</code></a>. This an ARM instruction that does floating point multiply and add, but on a <em>vector</em> of four values, rather than a <em>scalar</em> of one value. Also, notice the subtraction in register <code class="language-plaintext highlighter-rouge">x17</code> - it now iterates the loop counter by 4, instead of 1. Each time through the unrolled loop, we get four operations, not just one.</p> <p>We can confirm this by running the Samply profiler:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>samply record ./matmul
</code></pre></div></div> <p><img src="/static/images/learning-loop-unrolling/samply_matmul.png" alt="samply_matmul.png" title="Screen shot of Samply output for matmul, showing 327 calls to decrement the loop counter"></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>samply record ./matmul_unrolled4
</code></pre></div></div> <p><img src="/static/images/learning-loop-unrolling/samply_matmul_unrolled4.png" alt="samply_matmul.png" title="Screen shot of Samply output for matmul_unrolled4, showing 92 calls to decrement the loop counter"></p> <p>While Samply does not report exactly four times fewer calls to the loop decrement, it is pretty close. The unrolled inner loop is doing significantly fewer iterations.</p> <h2 id="compilers-️-processors">Compilers ❤️ Processors</h2> <p>What is really going on here?</p> <p>By telling the Mojo compiler to unroll that inner loop, we’re giving it a better chance to use the available hardware. ARMv8-A processors (like the ones in my Mac) have 32 <a href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/NEON-and-floating-point-registers/Scalar-register-sizes" rel="external nofollow noopener" target="_blank">registers</a> that are 128 bits wide. The “S” prefix from the normal assembly code means “Word”, or a 32-bit value. The “Q” prefix from the unrolled assembly code means “Quadword”, or a 128-bit value.</p> <p>In this example our data type is 32-bit floating point values, so the normal example is not using all of the available register space. It is only using 32 bits (one-fourth) of registers <code class="language-plaintext highlighter-rouge">s0</code>, <code class="language-plaintext highlighter-rouge">s1</code>, and <code class="language-plaintext highlighter-rouge">s2</code> during each loop. But with the unrolled loop, the compiler is able to notice the chance to “vectorize” the code, and use the full width of each 128-bit register, where it can put four 32-bit floating point values side by side, and then use the <code class="language-plaintext highlighter-rouge">fmla</code> instruction to compute the multiply and add operation on all four together. The ARM <a href="https://developer.arm.com/documentation/den0024/a/ARMv8-Registers/NEON-and-floating-point-registers/Vector-register-sizes" rel="external nofollow noopener" target="_blank">documentation</a> explains the interesting <code class="language-plaintext highlighter-rouge">.4s</code> syntax on each of the arguments to <code class="language-plaintext highlighter-rouge">fmla</code>.</p> <blockquote> <p>Vn.4S - 4 lanes, each containing a 32-bit element</p> </blockquote> <p>So the compiler is able to more efficiently use the registers available on this process.</p> <p>Why do we need to manually unroll the inner loop to allow the compiler to see this possible optimization? I’m not entirely sure. I suspect the compiler has some limited budget for time spent on loop analysis. After all, we want our to to compile fast as well.</p> <h2 id="where-to-next">Where to next?</h2> <p>This example is certainly not the best possible matrix multiplication algorithm. The Modular documentation linked above goes into much more detail about techniques to improve its performance. But it does give us a fun little insight into loop unrolling though, and specifically into how it is implemented in Mojo. I wonder what this example looks like in other languages.</p> <h2 id="appendix">Appendix</h2> <p>Notice in the benchmarking data for the unrolled inner loop, we get slightly better performance as we unroll that inner loop more and more. Skipping by 8, 16, and eventually 32 iterations each yields small marginal gains - but why?</p> <p>The assembly for the <code class="language-plaintext highlighter-rouge">@unroll(32)</code> case provides a hint:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LAB_1000016dc 
ldp        q1,q2,[x17, #-0x40]
ldp        q3,q4,[x16, #-0x40]
fmla       v3.4S,v0.4S,v1.4S
fmla       v4.4S,v0.4S,v2.4S
stp        q3,q4,[x16, #-0x40]
ldp        q1,q2,[x17, #-0x20]
ldp        q3,q4,[x16, #-0x20]
fmla       v3.4S,v0.4S,v1.4S
fmla       v4.4S,v0.4S,v2.4S
stp        q3,q4,[x16, #-0x20]
ldp        q1,q2,[x17]
ldp        q3,q4,[x16]
fmla       v3.4S,v0.4S,v1.4S
fmla       v4.4S,v0.4S,v2.4S
stp        q3,q4,[x16]
ldp        q1,q2,[x17, #0x20]
ldp        q3,q4,[x16, #0x20]
fmla       v3.4S,v0.4S,v1.4S
fmla       v4.4S,v0.4S,v2.4S
stp        q3,q4,[x16, #0x20]
sub        x0,x0,#0x20
add        x17,x17,#0x80
add        x16,x16,#0x80
cmp        x0,#0x20
b.hi       LAB_1000016dc
</code></pre></div></div> <p>There are eight <code class="language-plaintext highlighter-rouge">fmla</code> instructions, set up in four pairs, where each instruction in a given pair is using different result registers. I’m not sure how the Apple M2 implementation works, but I suspect it can take advantage of hardware-level parallelism here, and exec both of the <code class="language-plaintext highlighter-rouge">fmla</code> instructions in a pair at the same time. It sounds like I have more to explore!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/more-fun-with-loop-unrolling-cpp/">More fun with loop unrolling - C++</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/constraints-are-liberating/">Constraints are liberating</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/span-making-c-arrays-fun-since-2020/">Span - making C arrays fun since 2020</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/game-theory-fun-in-the-nfl/">Game theory fun in the NFL</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/docker-for-c-plus-plus-builds/">Docker for C++ builds</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Josh Peterson. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: March 16, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>